.\" Version: 0.160.24
.\"
.TH ocf_suse_SAPHanaController 7 "26 Oct 2016" "" "OCF resource agents"
.\"
.SH NAME
SAPHanaController \- Manages take-over between two SAP HANA databases with system replication.
.PP
.\"
.SH SYNOPSYS
\fBSAPHanaController\fP [start | stop | status | monitor | promote | demote | notify | meta\-data | validate\-all | methods | usage ]
.PP
.\"
.SH DESCRIPTION

This SAPHanaController is a resource agent for SAP HANA databases in 
scale-out setups. It manages take-over for a SAP HANA database with 
system replication in an OCF master/slave configuration.
.PP
System replication will help to replicate the database data from one site to
another site in order to compensate for database failures. With this mode of
operation, internal SAP HANA high-availability (HA) mechanisms and the resource
agent have to work together.
.PP
An HANA scale-out setup already is, to some degree, an HA cluster on its own.
The HANA is able to replace failing nodes with standby nodes or to restart
certain sub-systems on other nodes. As long as the HANA landscape status is
not "ERROR" the Linux cluster will not act. The main purpose of the Linux
cluster is to handle the take-over to the other site. Only if the HANA
landscape status indicates that HANA can not recover from the failure and the
replication is in sync, then Linux will act. As an exception, the Linux cluster
will react if HANA moves the master nameserver role to another candidate. 
SAPHanaController is also able to restart former failed worker nodes as standby.
.PP
On initial cluster start, the cluster needs to detect a valid HANA system
replication setup, including system replication status (SOK) and last primary
timestamp (LPT). This is neccessary to ensure data integrity.
.PP
The SAPHanaController resource agent (RA) performs the actual check of the
SAP HANA database instances and is configured as a master/slave resource.
The Linux cluster resource's master status will follow the HANA's active master
name server role. Resources that need to run on the same node with that HANA
role should be co-located with the master target.
.\" TODO sketch to show relation between roles
.\" Linux Cluster (res) Linux Cluster (m/s)   HANA      
.\" Follow    <=>       Master     ==         Primary Name Server    
.PP
Managing the two SAP HANA instances in scale-out setup means that the resource
agent controls the start/stop of the instances. In addition the resource agent
is able to monitor the SAP HANA databases on landscape host configuration level.
For this monitoring the resource agent relies on interfaces provided by SAP.
A third task of the resource agent is to also check the synchronisation status
of the two SAP HANA databases. If the synchronisation is not "SOK", then the
cluster avoids to take-over to the secondary side, if the primary fails. This
is to improve the data consistency.
.PP
The resource agent uses the following five interfaces provided by SAP:
.PP
1. \fBsapcontrol/sapstartsrv\fP
.br
The interface sapcontrol/sapstartsrv is used to start/stop a HANA
database instance/system
.PP
2. \fBlandscapeHostConfiguration\fP
.br
The interface is used to monitor a HANA system. The python script is named
landscapeHostConfiguration.py.
landscapeHostConfiguration.py has some detailed output about HANA system status
and node roles. For our monitor the overall status is relevant.
This overall status is reported by the returncode of the script:
0: Internal Fatal, 1: ERROR, 2: WARNING, 3: INFO, 4: OK
The SAPHanaController resource agent will interpret returncode 0 as FATAL,
1 as not-running (or ERROR) and returncodes 2+3+4 as RUNNING.
.PP
3. \fBhdbnsutil\fP
.br
The interface hdbnsutil is used to check the "topology" of the system
replication as well as the current configuration (primary/secondary) of a
SAP HANA database instance. A second task of the interface is the posibility
to run a system replication take-over (sr_takeover) or to register a former
primary to a newer one (sr_register). In scale-out setups, hdbnsutil sometimes
might take some time.
.PP
4. \fBsystemReplicationStatus\fP
.br
The Interface is systemReplicationStatus is a special query into HANA 
(system replication table) via a python library. 
This interface exists since SAP HANA SPS9.
.PP
5. \fBsaphostctrl\fP
.br
The interface saphostctrl uses the function ListInstances to figure out the
virtual host name of the SAP HANA instance. This is the hostname used during
the HANA installation.
.PP
To make configuring the cluster as simple as possible, the additional
SAPHanaTopology resource agent runs on all nodes of the Linux cluster and
gathers information about the statuses and configurations of SAP HANA system
replication. The SAPHanaTopology RA is designed as a normal (stateless) clone.
.PP  
Please see also the REQUIREMENTS section below.
.RE
.PP
.\"
.SH SUPPORTED PARAMETERS
This resource agent supports the following parameters:
.PP
\fBSID\fR
.RS 4
SAP System Identifier. Has to be same on both instances.
.RE
.PP
\fBInstanceNumber\fR
.RS 4
Number of the SAP HANA database.
For system replication also Instance Number+1 is blocked.
.RE
.PP
\fBDIR_EXECUTABLE\fR
.RS 4
The full qualified path where to find sapstartsrv and sapcontrol.
Specify this parameter, if you have changed the SAP kernel directory
location after the default SAP installation.
.br
Optional, well known directories will be searched by default.
.RE
.PP
\fBDIR_PROFILE\fR
.RS 4
The full qualified path where to find the SAP START profile.
Specify this parameter, if you have changed the SAP profile directory
location after the default SAP installation.
.br
Optional, well known directories will be searched by default.
.RE
.PP
\fBINSTANCE_PROFILE\fR
.RS 4
The name of the SAP HANA instance profile. Specify this parameter,
if you have changed the name of the SAP HANA instance profile
after the default SAP installation.
Normally you do not need to set this parameter.
.br
Optional, well known directories will be searched by default.
.RE 
.PP
\fBPREFER_SITE_TAKEOVER\fR
.RS 4
Defines whether RA should prefer to take-over to the slave database
instead of restarting master locally. However a take-over will only
be triggered, if the SAP HANA landscape status is on "ERROR".
.br
Optional. Default value: true\&.
.RE
.PP
\fBDUPLICATE_PRIMARY_TIMEOUT\fR
.RS 4
Time difference needed between two primary time stamps, if a
dual-primary situation occurs. If the time difference is less than
the time gap, than the cluster holds one or both instances in a
"WAITING" status. This is to give an admin a chance to react on a
take-over. A failed former primary will be registered after the time
difference is passed. After this registration to the new primary all
data will be overwritten by the system replication.
.br
Optional. Default value: 7200\&.
.RE
.PP
\fBAUTOMATED_REGISTER\fR
.RS 4
Defines whether a former primary database should be registered
automatically by the resource agent during cluster/resource start,
if the DUPLICATE_PRIMARY_TIMEOUT is expired.
.br
Default value: false\&.
.RE
.PP
.\"
.SH SUPPORTED PROPERTIES
.br
\fBhana_${sid}_glob_filter\fR
.RS 4
Global cluster property \fBhana_${sid}_glob_filter\fR .
This property should only be set if requested by support engineers.
The default is sufficient for normal operation.
.RE
.PP
.\"
.SH SUPPORTED ACTIONS
This resource agent supports the following actions (operations):
.PP
\fBstart\fR
.RS 4
Starts the HANA instance or bring the "clone instance" to a WAITING status.
Suggested minimum timeout: 3600\&.
.RE
.PP
\fBstop\fR
.RS 4
Stops the HANA instance. 
Suggested minimum timeout: 3600\&.
.RE
.PP
\fBpromote\fR
.RS 4
Either runs a take-nover for a secondary or a just-nothing for a primary.
Suggested minimum timeout: 900\&.
.RE
.PP
\fBdemote\fR
.RS 4
Nearly does nothing and just marks the instance as demoted.
Suggested minimum timeout: 320\&.
.RE
.PP
\fBnotify\fR
.RS 4
Always returns SUCCESS.
Suggested minimum timeout: 10\&.
.RE
.PP
\fBstatus\fR
.RS 4
Reports whether the HANA instance is running.
Suggested minimum timeout: 60\&.
.RE
.PP
\fBmonitor (Master role)\fR
.RS 4
Reports whether the HANA database seems to be working in
master/slave it also needs to check the system replication status.
Suggested minimum timeout: 700\&.
Suggested interval: 60\&.
.RE
.PP
\fBmonitor (Slave role)\fR
.RS 4
Reports whether the HANA database seems to be working in
master/slave it also needs to check the system replication status.
Suggested minimum timeout: 700\&.
Suggested interval: 61\&.
.RE
.PP
\fBvalidate\-all\fR
.RS 4
Reports whether the parameters are valid.
Suggested minimum timeout: 5\&.
.RE
.PP
\fBmeta\-data\fR
.RS 4
Retrieves resource agent metadata (internal use only).
Suggested minimum timeout: 5\&.
.RE
.PP
\fBmethods\fR
.RS 4
Suggested minimum timeout: 5\&.
.RE
.PP
.\"
.SH RETURN CODES
The return codes are defined by the OCF cluster framework.
Please refer to the OCF definition on the website mentioned below. 
.br
In addition, log entries are written, which can be scanned by using a
pattern like "SAPHanaController.*RA.*rc=[1-7,9]" for errors.
Regular operations might be found with "SAPHanaController.*RA.*rc=0".
.PP
.\"
.SH EXAMPLES
.\" .PP
.\" * This is an example configuration for a SAPHanaController resource for HANA scale-up.
.\" .br
.\" In addition, a SAPHanaTopology resource is needed to make this work.
.\" .RE
.\" .PP
.\" .RS 4
.\" primitive rsc_SAPHanaController_SLE_HDB00 ocf:suse:SAPHanaController \\
.\" .br
.\" operations $id="rsc_sap_SLE_HDB00-operations" \\
.\" .br
.\" op start interval="0" timeout="3600" \\
.\" .br
.\" op stop interval="0" timeout="3600" \\
.\" .br
.\" op promote interval="0" timeout="3600" \\
.\" .br
.\" op monitor interval="60" role="Master" timeout="700" \\
.\" .br
.\" op monitor interval="61" role="Slave" timeout="700" \\
.\" .br
.\" params SID="SLE" InstanceNumber="00" PREFER_SITE_TAKEOVER="true" \\
.\" .br
.\" DUPLICATE_PRIMARY_TIMEOUT="7200" AUTOMATED_REGISTER="false"
.\" .PP
.\" ms msl_SAPHanaController_SLE_HDB00 rsc_SAPHanaController_SLE_HDB00 \\
.\" .br
.\" clone-max="2" clone-node-max="1"
.\" .RE
.PP
* Below is an example configuration for a SAPHanaTopology resource for
HANA scale-out.
.br
The HANA consists of two sites with five nodes each. An additional
cluster node is used as majority maker for split-brain situations.
In addition, a SAPHanaController resource is needed to make this work.
.RE
.PP
.RS 4
primitive rsc_SAPHanaCon_SLE_HDB00 ocf:suse:SAPHanaController \\
.br
op start interval="0" timeout="3600" \\
.br
op stop interval="0" timeout="3600" \\
.br
op promote interval="0" timeout="3600" \\
.br
op monitor interval="60" role="Master" timeout="700" \\
.br
op monitor interval="61" role="Slave" timeout="700" \\
.br
params SID="SLE" InstanceNumber="00" PREFER_SITE_TAKEOVER="false" \\
.br
DUPLICATE_PRIMARY_TIMEOUT="7200" AUTOMATED_REGISTER="false"
.PP
ms msl_SAPHanaCon_SLE_HDB00 rsc_SAPHanaCon_SLE_HDB00 \\
.br
master-node-max="1" master-max="1" clone-node-max="1" interleave="true"
.PP
location SAPHanaCon_not_on_majority_maker msl_SAPHanaCon_HAE_HDB00 -inf: vm-majority
.RE
.PP
* The following shows the filter for log messages set to the defaults.
.br
This property should only be set if requested by support engineers.
The default is sufficient for normal operation.
.RE
.PP
.RS 4
property $id="SAPHanaSR" \\
.br
hana_SLE_glob_filter="ra-act-dec-lpa"
.RE
.TP
* Search for log entries of the resource agent, show errors only:
.PP
.RS 4
# grep "SAPHanaController.*RA.*rc=[1-7,9]" /var/log/messages
.\" TODO: output
.RE
.PP
* Check for working NTP service:
.PP
.RS 4
# ntpq -p
.\" TODO:
.\"     remote           refid      st t when poll reach   delay   offset  jitter
.\"==============================================================================
.\" LOCAL(0)        .LOCL.          10 l   29   64  177    0.000    0.000   0.001
.\"*129.70.132.32   129.70.130.71    2 u   25   64  177   24.844  -25796.   9.929
.\"+141.30.228.4    5.9.110.236      3 u   32   64   77   37.789  -25795.   4.910
.RE
.PP
.\"
.SH FILES
.TP
/usr/lib/ocf/resource.d/suse/SAPHanaController
    the resource agent
.TP
/usr/lib/ocf/resource.d/suse/SAPHanaTopology
    the also needed topology resource agent
.TP
/usr/sap/$SID/$InstanceName/exe
    default path for DIR_EXECUTABLE
.TP
/usr/sap/$SID/SYS/profile
    default path for DIR_PROFILE
.\"
.\" TODO: INSTANCE_PROFILE
.PP
.\"
.SH REQUIREMENTS
For the current version of the SAPHanaController resource agent that comes with
the software package SAPHanaSR-ScaleOut, the support is limited to the
scenarios and parameters described in the respective manual page
SAPHanaSR-ScaleOut(7).
.PP
.\"
.SH SEE ALSO
\fBocf_suse_SAPHanaTopology\fP(7) , \fBSAPHanaSR-monitor\fP(8) , \fBIPaddr2\fP(8) ,
\fBSAPHanaSR-showAttr\fP(8) , \fBSAPHanaSR-ScaleOut\fP(7) ,
\fBntp.conf\fP(5) , \fBstonith\fP(8) 
.br
https://www.suse.com/products/sles-for-sap/resource-library/sap-best-practices.html ,
.br
http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html/Pacemaker_Explained/s-ocf-return-codes.html ,
.br
http://scn.sap.com/community/hana-in-memory/blog/2014/04/04/fail-safe-operation-of-sap-hana-suse-extends-its-high-availability-solution ,
.br
http://www.saphana.com/docs/DOC-2775 ,
.br
http://scn.sap.com/docs/DOC-60334 ,
.br
http://scn.sap.com/docs/DOC-65899
.PP
.\"
.SH AUTHORS
F.Herschel, L.Pinne.
.PP
.\"
.SH COPYRIGHT
(c) 2014 SUSE Linux Products GmbH, Germany.
.br
(c) 2015-2016 SUSE Linux GmbH, Germany.
.br
The resource agent SAPHanaController comes with ABSOLUTELY NO WARRANTY.
.br
For details see the GNU General Public License at
http://www.gnu.org/licenses/gpl.html
.\"
